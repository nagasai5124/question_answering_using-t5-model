{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huTu5DbHdbHw",
        "outputId": "8ec8cfc2-d483-4cbd-ea57-4e2e134af26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/train-v1.1.json.zip\n",
            "  inflating: train-v1.1.json         \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/train-v1.1.json.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4D5I_d2eTFR"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HlLcUwoeYRF"
      },
      "outputs": [],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install blue"
      ],
      "metadata": {
        "id": "WUm5Zlg0sYPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F45w3gcHdbNY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision import transforms\n",
        "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2BFPBaHCdbRy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mufc5fhqqDUa"
      },
      "outputs": [],
      "source": [
        "with open('/content/train-v1.1.json') as f:\n",
        "  data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9udkpaLCq5oO"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4GW6DL6q6i_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d00f2180-562b-4a60-fa45-ffde85e5d402"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data['data'][0]['paragraphs'][0]['qas'][0]['question']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "articles=[]\n",
        "\n",
        "for article in data['data']:\n",
        "  for paragraph in article['paragraphs']:\n",
        "    for qa in paragraph['qas']:\n",
        "      inputs={\"context\": paragraph['context'],'question': qa['question'],'answers':qa['answers'][0]['text']}\n",
        "      articles.append(inputs)\n"
      ],
      "metadata": {
        "id": "Jozy5qkKsYf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articles[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJ0gtAVHtRkV",
        "outputId": "e79d1c2c-fced-4517-f989-d18e6a97643c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
              " 'question': 'What is in front of the Notre Dame Main Building?',\n",
              " 'answers': 'a copper statue of Christ'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.DataFrame(articles)"
      ],
      "metadata": {
        "id": "PCD2oDpStWnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IrErqBx9ti1m",
        "outputId": "a1fce5a2-97b8-4fa9-c60a-b7b162eb41ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  Architecturally, the school has a Catholic cha...   \n",
              "1  Architecturally, the school has a Catholic cha...   \n",
              "2  Architecturally, the school has a Catholic cha...   \n",
              "3  Architecturally, the school has a Catholic cha...   \n",
              "4  Architecturally, the school has a Catholic cha...   \n",
              "\n",
              "                                            question  \\\n",
              "0  To whom did the Virgin Mary allegedly appear i...   \n",
              "1  What is in front of the Notre Dame Main Building?   \n",
              "2  The Basilica of the Sacred heart at Notre Dame...   \n",
              "3                  What is the Grotto at Notre Dame?   \n",
              "4  What sits on top of the Main Building at Notre...   \n",
              "\n",
              "                                   answers  \n",
              "0               Saint Bernadette Soubirous  \n",
              "1                a copper statue of Christ  \n",
              "2                        the Main Building  \n",
              "3  a Marian place of prayer and reflection  \n",
              "4       a golden statue of the Virgin Mary  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a752b90a-28bc-40c6-acb5-071f73b6e362\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
              "      <td>Saint Bernadette Soubirous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is in front of the Notre Dame Main Building?</td>\n",
              "      <td>a copper statue of Christ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>The Basilica of the Sacred heart at Notre Dame...</td>\n",
              "      <td>the Main Building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What is the Grotto at Notre Dame?</td>\n",
              "      <td>a Marian place of prayer and reflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Architecturally, the school has a Catholic cha...</td>\n",
              "      <td>What sits on top of the Main Building at Notre...</td>\n",
              "      <td>a golden statue of the Virgin Mary</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a752b90a-28bc-40c6-acb5-071f73b6e362')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a752b90a-28bc-40c6-acb5-071f73b6e362 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a752b90a-28bc-40c6-acb5-071f73b6e362');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e68293b-b135-49d7-b09b-0698db18db15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e68293b-b135-49d7-b09b-0698db18db15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e68293b-b135-49d7-b09b-0698db18db15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 87599,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18891,\n        \"samples\": [\n          \"More commonly, in cases where there are three or more parties, no one party is likely to gain power alone, and parties work with each other to form coalition governments. This has been an emerging trend in the politics of the Republic of Ireland since the 1980s and is almost always the case in Germany on national and state level, and in most constituencies at the communal level. Furthermore, since the forming of the Republic of Iceland there has never been a government not led by a coalition (usually of the Independence Party and one other (often the Social Democratic Alliance). A similar situation exists in the Republic of Ireland; since 1989, no one party has held power on its own. Since then, numerous coalition governments have been formed. These coalitions have been exclusively led by one of either Fianna F\\u00e1il or Fine Gael. Political change is often easier with a coalition government than in one-party or two-party dominant systems.[dubious \\u2013 discuss] If factions in a two-party system are in fundamental disagreement on policy goals, or even principles, they can be slow to make policy changes, which appears to be the case now in the U.S. with power split between Democrats and Republicans. Still coalition governments struggle, sometimes for years, to change policy and often fail altogether, post World War II France and Italy being prime examples. When one party in a two-party system controls all elective branches, however, policy changes can be both swift and significant. Democrats Woodrow Wilson, Franklin Roosevelt and Lyndon Johnson were beneficiaries of such fortuitous circumstances, as were Republicans as far removed in time as Abraham Lincoln and Ronald Reagan. Barack Obama briefly had such an advantage between 2009 and 2011.\",\n          \"There has been some concern over the potential adverse environmental and ecosystem effects caused by the influx of visitors. Some environmentalists and scientists have made a call for stricter regulations for ships and a tourism quota. The primary response by Antarctic Treaty Parties has been to develop, through their Committee for Environmental Protection and in partnership with IAATO, \\\"site use guidelines\\\" setting landing limits and closed or restricted zones on the more frequently visited sites. Antarctic sightseeing flights (which did not land) operated out of Australia and New Zealand until the fatal crash of Air New Zealand Flight 901 in 1979 on Mount Erebus, which killed all 257 aboard. Qantas resumed commercial overflights to Antarctica from Australia in the mid-1990s.\",\n          \"After World War II, the Guam Organic Act of 1950 established Guam as an unincorporated organized territory of the United States, provided for the structure of the island's civilian government, and granted the people U.S. citizenship. The Governor of Guam was federally appointed until 1968, when the Guam Elective Governor Act provided for the office's popular election.:242 Since Guam is not a U.S. state, U.S. citizens residing on Guam are not allowed to vote for president and their congressional representative is a non-voting member.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 87355,\n        \"samples\": [\n          \"What metropolitan area is Portsmouth a part of?\",\n          \"What symbol did Abu Muslim use in his revolt against the Umayyads?\",\n          \"Who did Jesus say were his \\\"brother, and sister, and mother?\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answers\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65134,\n        \"samples\": [\n          \"subtropical\",\n          \"$20.67\",\n          \"Power Mac G4 Cube\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_len=0\n",
        "for i in data['answers']:\n",
        "  if len(i.split())>t_len:\n",
        "    t_len=len(i.split())\n",
        "print(t_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TS7MgiIvtkk5",
        "outputId": "a38be6bf-1777-4518-be14-3f20ac5d06fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_len=0\n",
        "for i in data['question']:\n",
        "  if len(i.split())>q_len:\n",
        "    q_len=len(i.split())\n",
        "print(q_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av8qAXINuvgG",
        "outputId": "4ec118e9-eae5-4083-dcc4-3bc3ba229975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=T5TokenizerFast.from_pretrained('t5-base')\n",
        "model=T5ForConditionalGeneration.from_pretrained('t5-base',return_dict=True)\n",
        "optimizer=Adam(model.parameters(),lr=0.00001)\n",
        "q_len=40\n",
        "t_len=43\n",
        "batch_size=4\n",
        "device= 'cuda'if torch.cuda.is_available() else 'cpu'\n",
        "epochs=5"
      ],
      "metadata": {
        "id": "aNi40i6rt8ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QeTipIAnutaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(self,data,tokenizer,q_len,t_len):\n",
        "    self.data=data\n",
        "    self.tokenizer=tokenizer\n",
        "    self.q_len=q_len\n",
        "    self.t_len=t_len\n",
        "    self.question=self.data['question'].tolist()\n",
        "    self.answer=self.data['answers'].tolist()\n",
        "    self.context=self.data['context'].tolist()\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    question=self.question[idx]\n",
        "    answer=self.answer[idx]\n",
        "    context=self.context[idx]\n",
        "\n",
        "    #print(question)\n",
        "    #print(answer)\n",
        "    #print(context)\n",
        "\n",
        "    question_token=self.tokenizer(question,max_length=self.q_len,padding='max_length',truncation=True,pad_to_max_length=True,add_special_tokens=True)\n",
        "    answer_token=self.tokenizer(answer,max_length=self.t_len,padding='max_length',truncation=True,pad_to_max_length=True,add_special_tokens=True)\n",
        "\n",
        "    labels=answer_token['input_ids']\n",
        "    labels[labels==0]=-100\n",
        "\n",
        "    return {\n",
        "        \"inputs_ids\":torch.tensor(question_token['input_ids'],dtype=torch.long),\n",
        "        \"attention_mask\":torch.tensor(question_token['attention_mask'],dtype=torch.long),\n",
        "        \"labels\":torch.tensor(labels,dtype=torch.long),\n",
        "        \"decoder_attention_mask\":torch.tensor(answer_token['attention_mask'],dtype=torch.long)\n",
        "    }\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wwYyw8JyvP4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data=QADataset(data,tokenizer,q_len,t_len)"
      ],
      "metadata": {
        "id": "NXFr0NiQxjKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ujhAhwxoM3",
        "outputId": "6b5af3fc-289f-41f9-eb81-dfbba3f0b609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inputs_ids': tensor([  304,  4068,   410,     8, 16823,  3790,     3, 18280,  2385,    16,\n",
              "           507,  3449,    16,   301,  1211,  1395,  1410,    58,     1,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
              " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
              " 'labels': tensor([-100, 8942,    9,   26, 1954,  264, 8371, 8283,    1,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "            0,    0,    0,    0,    0,    0,    0]),\n",
              " 'decoder_attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data,val_data=train_test_split(data,test_size=0.2,random_state=42)\n",
        "\n",
        "train_dataset=QADataset(train_data,tokenizer,q_len,t_len)\n",
        "val_dataset=QADataset(val_data,tokenizer,q_len,t_len)\n",
        "\n",
        "train_data_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
        "val_data_loader=DataLoader(val_dataset,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "jTlOxbzZxpZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_data_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-Y7TUr6zEuf",
        "outputId": "4ecc5148-437d-45c4-a369-ef9feb3107c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inputs_ids': tensor([[  571,    19, 11901,    31,     7,  1424,   512,     3,  8232,    58,\n",
              "              1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [ 2645,   410,    37,  3068, 15884,  1827, 22324,    13,    16,  6622,\n",
              "             58,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [  363,    19,     8,  2015,   496,   358,    16,  1117,  5089,    58,\n",
              "              1,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [ 1029,  4068,    47,  7332,  3558,    21,  1711,    58,     1,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " 'labels': tensor([[-100,  189, 2015,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0],\n",
              "         [-100, 1088,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0],\n",
              "         [-100, 1334, 2575, 1121, 2149,    1,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0],\n",
              "         [-100,   23, 3849,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "             0,    0,    0,    0,    0,    0,    0]]),\n",
              " 'decoder_attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBuCLlSWzHJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc6yXJXDCf_R",
        "outputId": "6c62832a-6270-46b7-e2f4-a03561c73488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss=0\n",
        "val_loss=0\n",
        "train_batch_count=0\n",
        "val_batch_count=0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  for batch in tqdm(train_data_loader):\n",
        "    inputs_ids=batch['inputs_ids'].to(device)\n",
        "    attention_mask=batch['attention_mask'].to(device)\n",
        "    labels=batch['labels'].to(device)\n",
        "    decoder_attention_mask=batch['decoder_attention_mask'].to(device)\n",
        "\n",
        "\n",
        "    output=model(input_ids=inputs_ids,\n",
        "                 attention_mask=attention_mask,\n",
        "                 labels=labels,\n",
        "                 decoder_attention_mask=decoder_attention_mask)\n",
        "    #print(output)\n",
        "    optimizer.zero_grad()\n",
        "    loss=output.loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss+=loss.item()\n",
        "    train_batch_count+=1\n",
        "    #print(loss)\n",
        "\n",
        "  print(f\"Train Loss: {train_loss/train_batch_count}\")"
      ],
      "metadata": {
        "id": "pAcGkZ2k0FEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "for batch in tqdm(val_data_loader):\n",
        "  inputs_ids=batch['inputs_ids'].to(device)\n",
        "  attention_mask=batch['attention_mask'].to(device)\n",
        "  labels=batch['labels'].to(device)\n",
        "  decoder_attention_mask=batch['decoder_attention_mask'].to(device)\n",
        "  with torch.no_grad():\n",
        "    output=model(input_ids=inputs_ids,\n",
        "                 attention_mask=attention_mask,\n",
        "                 labels=labels,\n",
        "                 decoder_attention_mask=decoder_attention_mask)\n",
        "    optimizer.zero_grad()\n",
        "    loss=output.loss\n",
        "    val_loss+=loss.item()\n",
        "    val_batch_count+=1\n",
        "  print(f\"{epoch+1}/{2} -> Train loss: {train_loss / train_batch_count}\\tValidation loss: {val_loss/val_batch_count}\")"
      ],
      "metadata": {
        "id": "ucJxzbqaAgHq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "56593d96-e57e-4a93-9713-0dfb416de3fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 4/4380 [00:00<04:10, 17.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3200398683547974\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3199824690818787\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.2340755065282185\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3304593563079834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 8/4380 [00:00<03:57, 18.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.6487142086029052\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5951141516367595\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4948115178516932\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.500336304306984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 12/4380 [00:00<04:01, 18.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4832775195439656\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4629136443138122\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5102866888046265\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4635957727829616\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 14/4380 [00:00<04:00, 18.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4997358643091643\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.475655083145414\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4321874101956686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 18/4380 [00:01<04:39, 15.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3940244391560555\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3951288601931404\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.363844417863422\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3408314177864475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 22/4380 [00:01<04:48, 15.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3212263464927674\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3039121826489766\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.2875331342220306\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.287826146768487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 26/4380 [00:01<04:19, 16.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.291819768647353\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3039742970466615\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.292497884768706\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.2842118055732161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 30/4380 [00:01<04:07, 17.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3243614115885325\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3421943043840343\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.365327384074529\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3701287911784263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 34/4380 [00:02<04:26, 16.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3590140137821436\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.352149556983601\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3531348477391636\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3471554262297494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 38/4380 [00:02<04:08, 17.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3497549874915018\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3648417527611192\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3568125759300433\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3622470436952052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 42/4380 [00:02<04:26, 16.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3669402495026588\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3545387619879188\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3803215892541976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 46/4380 [00:02<04:07, 17.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4139503892077956\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.4015375673770905\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3948443677690294\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3965937287911125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 50/4380 [00:02<04:09, 17.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.3926055025547108\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5168815006812413\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5459541009396922\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5698761558532714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 54/4380 [00:03<04:03, 17.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.572456584257238\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5894795931302583\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.598987804268891\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5932042201360066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|         | 58/4380 [00:03<03:59, 18.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.584083552794023\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5755424733672823\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5715726969534891\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5690518186010163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|         | 62/4380 [00:03<04:01, 17.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5848225597607888\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5865213672320049\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5842388184344183\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5869016628111563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 66/4380 [00:03<04:04, 17.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.579213019401308\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5696773137897253\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5670360711904672\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.559476760300723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 70/4380 [00:04<03:57, 18.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5904480432396504\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5984251341399025\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5865221645521081\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5923808864184787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 74/4380 [00:04<03:55, 18.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5879725284979378\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5932735684845183\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5873669761500946\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5869205255766172\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 78/4380 [00:04<03:48, 18.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.593367649714152\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.592194271715064\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5829293518871457\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5740732512412927\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 82/4380 [00:04<03:56, 18.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5797761339175551\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5776802606880664\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5691631178797028\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5611332720372735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 84/4380 [00:04<05:35, 12.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5525141458913505\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5580084444511504\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5529712487669551"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 86/4380 [00:05<05:40, 12.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5576401165751523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 88/4380 [00:05<05:39, 12.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5529949452685214\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.550241426310756\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5524479961127378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|         | 90/4380 [00:05<06:27, 11.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5534977588388654\n",
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5485746814654424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|         | 92/4380 [00:05<04:36, 15.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/2 -> Train loss: 6.0496930536234155\tValidation loss: 1.5575156270161918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-716d31dae02e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decoder_attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     output=model(input_ids=inputs_ids,\n\u001b[0m\u001b[1;32m      9\u001b[0m                  \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                  \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoder_outputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m             \u001b[0;31m# Convert encoder inputs in embeddings if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1854\u001b[0;31m             encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1855\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 )\n\u001b[1;32m   1123\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1125\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mcache_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     ):\n\u001b[0;32m--> 675\u001b[0;31m         self_attention_outputs = self.layer[0](\n\u001b[0m\u001b[1;32m    676\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xWyXoZ3cpCIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('qa_model')\n",
        "tokenizer.save_pretrained('qa_model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nI3G7KopC3T",
        "outputId": "d39ee36a-ffd6-46c7-8d5a-41e5f8b629df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('qa_model/tokenizer_config.json',\n",
              " 'qa_model/special_tokens_map.json',\n",
              " 'qa_model/spiece.model',\n",
              " 'qa_model/added_tokens.json',\n",
              " 'qa_model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69vM8qHypR9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ans(context,question,ref_ans=None):\n",
        "  inputs=tokenizer(question,context,max_length=q_len,padding='max_length',truncation=True,add_special_tokens=True).to(device)\n",
        "  inputs_ids=torch.tensor(inputs['input_ids'],dtype=torch.long).to(device).unsqueeze(0)\n",
        "  attention_mask=torch.tensor(inputs['attention_mask'],dtype=torch.long).to(device).unsqueeze(0)\n",
        "  output=model.generate(input_ids=inputs_ids,attention_mask=attention_mask)\n",
        "  predicted_ans=tokenizer.decode(output[0],skip_special_tokens=True)\n",
        "  if ref_ans:\n",
        "    rouge=evaluate.load('google_bleu')\n",
        "    #score=bleu.compute(predictions=[predicted_ans],references=[ref_ans])\n",
        "    print(\"context: \\n\",context,\"\\n\")\n",
        "    print(\"question: \\n\",question,\"\\n\")\n",
        "    return{\n",
        "      \"reference answer: \": ref_ans,\n",
        "      \"predicted answer: \": predicted_ans\n",
        "      #\"bleu score: \": score['bleu']\n",
        "    }\n",
        "  else:\n",
        "    return{\n",
        "      \"context: \": context,\n",
        "      \"question: \": question,\n",
        "      \"predicted answer: \": predicted_ans\n",
        "    }"
      ],
      "metadata": {
        "id": "B-__mGBdpSi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context=data.iloc[0]['context']\n",
        "question=data.iloc[0]['question']\n",
        "ref_ans=data.iloc[0]['answers']"
      ],
      "metadata": {
        "id": "73xHdv14rFwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_ans(context,question,ref_ans)"
      ],
      "metadata": {
        "id": "9EKEE4c8sQJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dcujpL1DsSAj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}